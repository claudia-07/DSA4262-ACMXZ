{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Files for Parsing\n",
    "#### If files are already parsed, head to the next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_path = \"/Users/claudia/Downloads/Project 2/data.json\"\n",
    "info_data_path = \"/Users/claudia/Downloads/Project 2/data.info\"\n",
    "data = [json.loads(line) for line in open(json_data_path, 'r')]\n",
    "with open(info_data_path, 'r') as f:\n",
    "    info = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(dictionary):\n",
    "    key_object = dictionary.keys()\n",
    "    key = list(key_object)[0]\n",
    "    return key\n",
    "\n",
    "def concat_col(transcript, position, nucleotide, reads, n):\n",
    "    t_df = pd.DataFrame([transcript]*n)\n",
    "    p_df = pd.DataFrame([position]*n)\n",
    "    nu_df = pd.DataFrame([nucleotide]*n)\n",
    "\n",
    "    ## concat columns together\n",
    "    final_df = pd.concat([t_df, p_df, nu_df, reads], axis = 1)\n",
    "    final_df.columns = ['transcript', 'position', 'nucleotides', 'dwelling_time', 'std', 'mean']\n",
    "    return final_df\n",
    "\n",
    "def parse_line(line):\n",
    "    ## get transcript\n",
    "    t = get_key(line)\n",
    "    \n",
    "    ## get position\n",
    "    p_0 = get_key(line[t])\n",
    "    p_minus1 = str(int(p_0) - 1)\n",
    "    p_plus1 = str(int(p_0) + 1)\n",
    "\n",
    "    ## get nucleotide seq and slice into 5 nucleotides for each position\n",
    "    nu = get_key(line[t][p_0])\n",
    "    nu_minus1 = nu[0:5]\n",
    "    nu_0 = nu[1:6]\n",
    "    nu_plus1 = nu[2:]\n",
    "\n",
    "    ## get number of reads\n",
    "    nb = len(line[t][p_0][nu])\n",
    "\n",
    "    ## get dataframe of list of reads\n",
    "    reads = pd.DataFrame(line[t][p_0][nu])\n",
    "    reads_minus1 = reads.iloc[:, :3]\n",
    "    reads_0 = reads.iloc[:, 3:6]\n",
    "    reads_plus1 = reads.iloc[:, 6:]\n",
    "\n",
    "    ## concat columns together to create position -1, 0, +1 dataframe respectively\n",
    "    df_minus1 = concat_col(t, p_minus1, nu_minus1, reads_minus1, nb)\n",
    "    df_0 = concat_col(t, p_0, nu_0, reads_0, nb)\n",
    "    df_plus1 = concat_col(t, p_plus1, nu_plus1, reads_plus1, nb)\n",
    "\n",
    "    ## concat rows together\n",
    "    merged_df = pd.concat([df_minus1, df_0, df_plus1], axis = 0)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parse all lines into dataframe for concatenation\n",
    "reads_df = [parse_line(data[i]) for i in range(len(data))]\n",
    "\n",
    "## concat reads dataframes\n",
    "data_df = pd.concat(reads_df, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(data_df)\n",
    "\n",
    "def save_file(dataframe, start, stop, filename):\n",
    "    pd.DataFrame(dataframe.iloc[start:stop, :]).to_parquet(filename)\n",
    "\n",
    "## split data into 5 files to save and upload\n",
    "save_file(data_df, 0, 5000000, \"data_1.parquet\")\n",
    "save_file(data_df, 5000000, 10000000, \"data_2.parquet\")\n",
    "save_file(data_df, 10000000, 15000000, \"data_3.parquet\")\n",
    "save_file(data_df, 15000000, 20000000, \"data_4.parquet\")\n",
    "save_file(data_df, 20000000, 25000000, \"data_5.parquet\")\n",
    "save_file(data_df, 25000000, 30000000, \"data_6.parquet\")\n",
    "save_file(data_df, 30000000, total_rows, \"data_7.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform info data into dataframe\n",
    "info_list = [info[i].split(\",\") for i in range(len(info))]\n",
    "info_df = pd.DataFrame(info_list[1:]) \n",
    "info_df.columns = info_list[0]\n",
    "info_df.to_parquet(\"info.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Parsed Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_parquet(\"/Users/claudia/Downloads/Project 2/data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left Join DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = data_df.merge(info_df, how = \"left\", left_on = [\"transcript\", \"position\"], right_on = [\"transcript_id\", \"transcript_position\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = complete_df[['transcript', 'position', 'nucleotides', 'dwelling_time', 'std', 'mean', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>nucleotides</th>\n",
       "      <th>dwelling_time</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>243</td>\n",
       "      <td>AAGAC</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>243</td>\n",
       "      <td>AAGAC</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>2.53</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>243</td>\n",
       "      <td>AAGAC</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>3.92</td>\n",
       "      <td>109.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>243</td>\n",
       "      <td>AAGAC</td>\n",
       "      <td>0.00398</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>243</td>\n",
       "      <td>AAGAC</td>\n",
       "      <td>0.00664</td>\n",
       "      <td>2.92</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transcript position nucleotides  dwelling_time   std   mean label\n",
       "0  ENST00000000233      243       AAGAC        0.00299  2.06  125.0   NaN\n",
       "1  ENST00000000233      243       AAGAC        0.00631  2.53  125.0   NaN\n",
       "2  ENST00000000233      243       AAGAC        0.00465  3.92  109.0   NaN\n",
       "3  ENST00000000233      243       AAGAC        0.00398  2.06  125.0   NaN\n",
       "4  ENST00000000233      243       AAGAC        0.00664  2.92  120.0   NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split data into 5 files to save and upload\n",
    "save_file(complete_df, 0, 5000000, \"merged_data_1.parquet\")\n",
    "save_file(complete_df, 5000000, 10000000, \"merged_data_2.parquet\")\n",
    "save_file(complete_df, 10000000, 15000000, \"merged_data_3.parquet\")\n",
    "save_file(complete_df, 15000000, 20000000, \"merged_data_4.parquet\")\n",
    "save_file(complete_df, 20000000, 25000000, \"merged_data_5.parquet\")\n",
    "save_file(complete_df, 25000000, 30000000, \"merged_data_6.parquet\")\n",
    "save_file(complete_df, 30000000, len(complete_df), \"merged_data_7.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
