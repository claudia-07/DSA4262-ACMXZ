{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "\n",
    "1. Identify datasets to be predicted\n",
    "2. Parse the datasets into dataframes\n",
    "3. Perform pre-processing on dataframes\n",
    "4. Train chosen model on full training data\n",
    "5. Predict labels for all datasets\n",
    "6. Save predictions into CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify datasets to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## libraries to read and parse json file\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/claudia/DSA4262-ACMXZ/prediction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset1.json', 'dataset2.json', 'dataset3.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change directory to data\n",
    "os.chdir(\"../data/final round/\")\n",
    "files = []\n",
    "\n",
    "## find which files to parse\n",
    "for filename in os.listdir(\".\"):\n",
    "    if filename.endswith(\".json\"):\n",
    "        files.append(filename)\n",
    "\n",
    "files.sort()\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse datasets into dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions needed to parse json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to get key of a dictionary\n",
    "def get_key(dictionary):\n",
    "    key_object = dictionary.keys()\n",
    "    key = list(key_object)[0]\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to help concatenate columns to get transcript, position, nucleotides\n",
    "def concat_col(transcript, position, nucleotide, n):\n",
    "    t_df = pd.DataFrame([transcript]*n)\n",
    "    p_df = pd.DataFrame([position]*n)\n",
    "    nu_df = pd.DataFrame([nucleotide]*n)\n",
    "    n_df = pd.DataFrame([n]*n)\n",
    "\n",
    "    ## concat columns together\n",
    "    final_df = pd.concat([t_df, p_df, nu_df, n_df], axis = 1)\n",
    "    final_df.columns = ['transcript', 'position', 'nucleotides', 'reads_count']\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to parse line in json file\n",
    "def parse_line(line):\n",
    "    ## get transcript\n",
    "    t = get_key(line)\n",
    "\n",
    "    ## get position\n",
    "    p = get_key(line[t])\n",
    "\n",
    "    ## get nucleotide seq\n",
    "    nu = get_key(line[t][p])\n",
    "\n",
    "    ## get number of reads\n",
    "    reads_count = len(line[t][p][nu])\n",
    "\n",
    "    ## get dataframe of list of reads\n",
    "    reads = pd.DataFrame(line[t][p][nu])\n",
    "\n",
    "    ## concat columns together to get transcript, position, nucleotides and all dwelling time, std, mean\n",
    "    df = pd.concat([concat_col(t, p, nu, reads_count), reads], axis = 1)\n",
    "    df.columns = ['transcript', 'position', 'nucleotides', 'reads_count', 'dwellingtime_-1', 'std_-1', 'mean_-1', 'dwellingtime_0', 'std_0', 'mean_0', 'dwellingtime_+1', 'std_+1', 'mean_+1']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Dataset 1 = (7907952, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>nucleotides</th>\n",
       "      <th>reads_count</th>\n",
       "      <th>dwellingtime_-1</th>\n",
       "      <th>std_-1</th>\n",
       "      <th>mean_-1</th>\n",
       "      <th>dwellingtime_0</th>\n",
       "      <th>std_0</th>\n",
       "      <th>mean_0</th>\n",
       "      <th>dwellingtime_+1</th>\n",
       "      <th>std_+1</th>\n",
       "      <th>mean_+1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>165</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>2.16</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.00640</td>\n",
       "      <td>3.90</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.00797</td>\n",
       "      <td>8.75</td>\n",
       "      <td>83.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>165</td>\n",
       "      <td>0.02690</td>\n",
       "      <td>4.43</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>10.00</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.00863</td>\n",
       "      <td>6.20</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>165</td>\n",
       "      <td>0.00432</td>\n",
       "      <td>3.10</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>8.26</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.01590</td>\n",
       "      <td>2.89</td>\n",
       "      <td>78.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>165</td>\n",
       "      <td>0.00996</td>\n",
       "      <td>4.52</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.01750</td>\n",
       "      <td>8.51</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>2.63</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>165</td>\n",
       "      <td>0.00764</td>\n",
       "      <td>2.81</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.00772</td>\n",
       "      <td>4.22</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.00474</td>\n",
       "      <td>5.84</td>\n",
       "      <td>80.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transcript position nucleotides  reads_count  dwellingtime_-1  std_-1  \\\n",
       "0  ENST00000000233      244     AAGACCA          165          0.00465    2.16   \n",
       "1  ENST00000000233      244     AAGACCA          165          0.02690    4.43   \n",
       "2  ENST00000000233      244     AAGACCA          165          0.00432    3.10   \n",
       "3  ENST00000000233      244     AAGACCA          165          0.00996    4.52   \n",
       "4  ENST00000000233      244     AAGACCA          165          0.00764    2.81   \n",
       "\n",
       "   mean_-1  dwellingtime_0  std_0  mean_0  dwellingtime_+1  std_+1  mean_+1  \n",
       "0    127.0         0.00640   3.90   127.0          0.00797    8.75     83.7  \n",
       "1    106.0         0.01860  10.00   123.0          0.00863    6.20     80.0  \n",
       "2    108.0         0.01200   8.26   125.0          0.01590    2.89     78.7  \n",
       "3    123.0         0.01750   8.51   128.0          0.00498    2.63     80.0  \n",
       "4    124.0         0.00772   4.22   126.0          0.00474    5.84     80.9  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## open dataset_1 json file\n",
    "data1 = [json.loads(line) for line in open(files[0], 'r')]\n",
    "\n",
    "## parse all lines into dataframes\n",
    "data1_reads = [parse_line(data1[i]) for i in range(len(data1))]\n",
    "\n",
    "## concatenate dataframes\n",
    "data1_df = pd.concat(data1_reads, axis = 0)\n",
    "\n",
    "print(f\"Shape of Dataset 1 = {data1_df.shape}\")\n",
    "data1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Dataset 2 = (6903936, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>nucleotides</th>\n",
       "      <th>reads_count</th>\n",
       "      <th>dwellingtime_-1</th>\n",
       "      <th>std_-1</th>\n",
       "      <th>mean_-1</th>\n",
       "      <th>dwellingtime_0</th>\n",
       "      <th>std_0</th>\n",
       "      <th>mean_0</th>\n",
       "      <th>dwellingtime_+1</th>\n",
       "      <th>std_+1</th>\n",
       "      <th>mean_+1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT1G01050.1</td>\n",
       "      <td>155</td>\n",
       "      <td>GAAACTA</td>\n",
       "      <td>36</td>\n",
       "      <td>0.00232</td>\n",
       "      <td>1.93</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.01260</td>\n",
       "      <td>1.97</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.00421</td>\n",
       "      <td>1.50</td>\n",
       "      <td>95.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT1G01050.1</td>\n",
       "      <td>155</td>\n",
       "      <td>GAAACTA</td>\n",
       "      <td>36</td>\n",
       "      <td>0.00896</td>\n",
       "      <td>2.27</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.00536</td>\n",
       "      <td>2.49</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.00797</td>\n",
       "      <td>2.28</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT1G01050.1</td>\n",
       "      <td>155</td>\n",
       "      <td>GAAACTA</td>\n",
       "      <td>36</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>6.29</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>2.07</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.00785</td>\n",
       "      <td>1.97</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT1G01050.1</td>\n",
       "      <td>155</td>\n",
       "      <td>GAAACTA</td>\n",
       "      <td>36</td>\n",
       "      <td>0.00617</td>\n",
       "      <td>5.16</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>2.70</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.00199</td>\n",
       "      <td>2.82</td>\n",
       "      <td>97.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G01050.1</td>\n",
       "      <td>155</td>\n",
       "      <td>GAAACTA</td>\n",
       "      <td>36</td>\n",
       "      <td>0.00664</td>\n",
       "      <td>2.01</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.00495</td>\n",
       "      <td>1.89</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.01100</td>\n",
       "      <td>1.64</td>\n",
       "      <td>97.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    transcript position nucleotides  reads_count  dwellingtime_-1  std_-1  \\\n",
       "0  AT1G01050.1      155     GAAACTA           36          0.00232    1.93   \n",
       "1  AT1G01050.1      155     GAAACTA           36          0.00896    2.27   \n",
       "2  AT1G01050.1      155     GAAACTA           36          0.00498    6.29   \n",
       "3  AT1G01050.1      155     GAAACTA           36          0.00617    5.16   \n",
       "4  AT1G01050.1      155     GAAACTA           36          0.00664    2.01   \n",
       "\n",
       "   mean_-1  dwellingtime_0  std_0  mean_0  dwellingtime_+1  std_+1  mean_+1  \n",
       "0    109.0         0.01260   1.97   111.0          0.00421    1.50     95.3  \n",
       "1    110.0         0.00536   2.49   110.0          0.00797    2.28     96.0  \n",
       "2    114.0         0.00442   2.07   111.0          0.00785    1.97     96.0  \n",
       "3    106.0         0.00830   2.70   105.0          0.00199    2.82     97.4  \n",
       "4    110.0         0.00495   1.89   110.0          0.01100    1.64     97.3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## open dataset_2 json file\n",
    "data2 = [json.loads(line) for line in open(files[1], 'r')]\n",
    "\n",
    "## parse all lines into dataframes\n",
    "data2_reads = [parse_line(data2[i]) for i in range(len(data2))]\n",
    "\n",
    "## concatenate dataframes\n",
    "data2_df = pd.concat(data2_reads, axis = 0)\n",
    "\n",
    "print(f\"Shape of Dataset 2 = {data2_df.shape}\")\n",
    "data2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5b4346411555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## open dataset_3 json file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## parse all lines into dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata3_reads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparse_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "## open dataset_3 json file\n",
    "data3 = [json.loads(line) for line in open(files[1], 'r')]\n",
    "\n",
    "## parse all lines into dataframes\n",
    "data3_reads = [parse_line(data3[i]) for i in range(len(data3))]\n",
    "\n",
    "## concatenate dataframes\n",
    "data3_df = pd.concat(data3_reads, axis = 0)\n",
    "\n",
    "print(f\"Shape of Dataset 3 = {data3_df.shape}\")\n",
    "data3_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform pre-processing on dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions needed for pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../util/model\"))\n",
    "from training import get_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng(df):\n",
    "    temp = pd.DataFrame(df.groupby(['gene_id', 'transcript', 'position', 'nucleotides', 'reads_count'], as_index=False)\n",
    "                           .agg({'dwellingtime_-1': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'std_-1': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'mean_-1': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'dwellingtime_0': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'std_0': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'mean_0': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'dwellingtime_+1': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'std_+1': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'mean_+1': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max]}))\n",
    "    temp.columns = ['gene_id', 'transcript', 'position', 'nucleotides', 'reads_count',\n",
    "                        'dwelling_time_-1_25', 'dwelling_time_-1_50', 'dwelling_time_-1_75', 'dwelling_time_-1_mean','dwelling_time_-1_min', 'dwelling_time_-1_max',\n",
    "                        'std_-1_25', 'std_-1_50', 'std_-1_75', 'std_-1_mean','std_-1_min', 'std_-1_max',\n",
    "                        'mean_-1_25', 'mean_-1_50', 'mean_-1_75', 'mean_-1_mean','mean_-1_min', 'mean_-1_max',\n",
    "                        'dwelling_time_0_25', 'dwelling_time_0_50', 'dwelling_time_0_75', 'dwelling_time_0_mean','dwelling_time_0_min','dwelling_time_0_max',\n",
    "                        'std_0_25', 'std_0_50', 'std_0_75', 'std_0_mean','std_0_min', 'std_0_max',\n",
    "                        'mean_0_25', 'mean_0_50', 'mean_0_75', 'mean_0_mean','mean_0_min', 'mean_0_max',\n",
    "                        'dwelling_time_+1_25', 'dwelling_time_+1_50', 'dwelling_time_+1_75', 'dwelling_time_+1_mean','dwelling_time_+1_min','dwelling_time_+1_max',\n",
    "                        'std_+1_25', 'std_+1_50', 'std_+1_75', 'std_+1_mean','std_+1_min', 'std_+1_max',\n",
    "                        'mean_+1_25', 'mean_+1_50', 'mean_+1_75', 'mean_+1_mean','mean_+1_min', 'mean_+1_max']\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_position(df):\n",
    "    df[\"position\"] = df[\"position\"].astype(int)\n",
    "\n",
    "    ## find relative position of each read in each transcript\n",
    "    df[\"relative_position\"] = df.groupby([\"transcript\", \"gene_id\"])[\"position\"].transform(lambda x: (x - x.min())/(x.max()-x.min()))\n",
    "\n",
    "    ## note: have NAs because there's transcripts with only one position\n",
    "    ## fill the NAs with 0\n",
    "    df[\"relative_position\"] = df[\"relative_position\"].fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(df, columns_to_map):\n",
    "    for i in range(7):\n",
    "        df['position_' + str(i)] = df['nucleotides'].apply(lambda x: x[i])\n",
    "        df_enc = pd.DataFrame({col: vals for vals, col in zip(pipe.transform(df).T, columns_to_map)})\n",
    "\n",
    "    return df_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform pre-processing on dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    ## get percentiles\n",
    "    percentile_df = feature_eng(df)\n",
    "    print(f\"After feature engineering, the shape is {percentile_df.shape}\")\n",
    "\n",
    "    ## get relative position\n",
    "    relative_pos_df = relative_position(percentile_df)\n",
    "    print(f\"After find the relative position, the shape is {relative_pos_df}\")\n",
    "\n",
    "    ## perform encoding\n",
    "    enc_df\n",
    "\n",
    "    return enc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_pp = preprocess(data1_df)\n",
    "data2_pp = preprocess(data2_df)\n",
    "data3_pp = preprocess(data3_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model on full training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, auc, accuracy_score, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in Train Set\n",
    "X_train_path = \"../data/preprocessed_data/training/X_train_enc.parquet\"\n",
    "X_train = pd.read_parquet(X_train_path)\n",
    "y_train_path = \"../data/preprocessed_data/training/y_train.parquet\"\n",
    "y_train = pd.read_parquet(y_train_path)\n",
    "\n",
    "### convert y_train into int\n",
    "y_train = y_train.values.ravel()\n",
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_features = ['std_-1_25', 'std_-1_50', 'std_-1_75', 'std_-1_mean', 'std_-1_min',\n",
    "       'mean_-1_25', 'mean_-1_50', 'mean_-1_75', 'mean_-1_mean', 'mean_-1_min',\n",
    "       'dwelling_time_0_50', 'dwelling_time_0_mean', 'std_0_25', 'std_0_50',\n",
    "       'std_0_75', 'std_0_mean', 'std_0_min', 'std_0_max', 'mean_0_25',\n",
    "       'mean_0_50', 'mean_0_75', 'mean_0_mean', 'mean_0_min', 'mean_0_max',\n",
    "       'dwelling_time_+1_mean', 'std_+1_25', 'std_+1_50', 'mean_+1_25',\n",
    "       'mean_+1_50', 'mean_+1_75', 'mean_+1_mean', 'mean_+1_min',\n",
    "       'mean_+1_max', 'relative_position', 'position_1_G', 'position_5_T']\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
