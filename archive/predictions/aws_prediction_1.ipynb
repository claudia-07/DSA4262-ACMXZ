{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_features = ['std_-1_25', 'std_-1_50', 'std_-1_75', 'std_-1_mean', 'std_-1_min',\n",
    "       'mean_-1_25', 'mean_-1_50', 'mean_-1_75', 'mean_-1_mean', 'mean_-1_min',\n",
    "       'dwelling_time_0_50', 'dwelling_time_0_mean', 'std_0_25', 'std_0_50',\n",
    "       'std_0_75', 'std_0_mean', 'std_0_min', 'std_0_max', 'mean_0_25',\n",
    "       'mean_0_50', 'mean_0_75', 'mean_0_mean', 'mean_0_min', 'mean_0_max',\n",
    "       'dwelling_time_+1_mean', 'std_+1_25', 'std_+1_50', 'mean_+1_25',\n",
    "       'mean_+1_50', 'mean_+1_75', 'mean_+1_mean', 'mean_+1_min',\n",
    "       'mean_+1_max', 'relative_position', 'position_1_G', 'position_5_T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled random forest model\n",
    "import joblib\n",
    "pickled_model = joblib.load('../modelling/rf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(csv_fpath):\n",
    "    ## read csv file\n",
    "    data = pd.read_csv(csv_fpath)\n",
    "    print(data.shape)\n",
    "\n",
    "    ## save transcript and position col for concatenation later\n",
    "    data_id_col = data[[\"transcript\", \"position\"]]\n",
    "\n",
    "    ## predict using rfc\n",
    "    data_pred = pickled_model.predict_proba(data[rfe_features])[:,1]\n",
    "    print(len(data_pred))\n",
    "\n",
    "    ## convert predictions to dataframe\n",
    "    data_pred_df = pd.DataFrame(data_pred, columns = ['score'])\n",
    "\n",
    "    ## \n",
    "    data_pred_df = pd.concat([data_id_col, data_pred_df], axis = 1)\n",
    "    print(f\"Prediction file is of shape: {data_pred_df.shape}\")\n",
    "\n",
    "    return data_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k562_rep4_run1_path = \"/Users/claudia/Downloads/K562_rep4_run1.csv\"\n",
    "k562_rep4_run1_pred = prediction(k562_rep4_run1_path)\n",
    "k562_rep4_run1_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k562_rep4_run1_pred.to_csv(\"data/aws_predictions/k562_rep4_run1_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116519, 76)\n",
      "116519\n",
      "Prediction file is of shape: (116519, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000371582</td>\n",
       "      <td>1030</td>\n",
       "      <td>0.004545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000371582</td>\n",
       "      <td>105</td>\n",
       "      <td>0.013636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000371582</td>\n",
       "      <td>1123</td>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000371582</td>\n",
       "      <td>147</td>\n",
       "      <td>0.072751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000371582</td>\n",
       "      <td>242</td>\n",
       "      <td>0.045583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transcript  position     score\n",
       "0  ENST00000371582      1030  0.004545\n",
       "1  ENST00000371582       105  0.013636\n",
       "2  ENST00000371582      1123  0.018182\n",
       "3  ENST00000371582       147  0.072751\n",
       "4  ENST00000371582       242  0.045583"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k562_rep5_run1_path = \"/Users/claudia/Downloads/K562_rep5_run1.csv\"\n",
    "k562_rep5_run1_pred = prediction(k562_rep5_run1_path)\n",
    "k562_rep5_run1_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k562_rep5_run1_pred.to_csv(\"../data/aws_predictions/k562_rep5_run1_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99502, 76)\n",
      "99502\n",
      "Prediction file is of shape: (99502, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1013</td>\n",
       "      <td>0.177273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1149</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>512</td>\n",
       "      <td>0.322727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>689</td>\n",
       "      <td>0.131818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>823</td>\n",
       "      <td>0.009091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transcript  position     score\n",
       "0  ENST00000373020      1013  0.177273\n",
       "1  ENST00000373020      1149  0.150000\n",
       "2  ENST00000373020       512  0.322727\n",
       "3  ENST00000373020       689  0.131818\n",
       "4  ENST00000373020       823  0.009091"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k562_rep6_run1_path = \"/Users/claudia/Downloads/K562_rep6_run1.csv\"\n",
    "k562_rep6_run1_pred = prediction(k562_rep6_run1_path)\n",
    "k562_rep6_run1_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k562_rep6_run1_pred.to_csv(\"../data/aws_predictions/k562_rep6_run1_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119481, 76)\n",
      "119481\n",
      "Prediction file is of shape: (119481, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.009091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1013</td>\n",
       "      <td>0.009091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1149</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>512</td>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>689</td>\n",
       "      <td>0.009091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transcript  position     score\n",
       "0  ENST00000373020      1006  0.009091\n",
       "1  ENST00000373020      1013  0.009091\n",
       "2  ENST00000373020      1149  0.000000\n",
       "3  ENST00000373020       512  0.018182\n",
       "4  ENST00000373020       689  0.009091"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcf7_rep3_run1_path = \"/Users/claudia/Downloads/MCF7_rep3_run1.csv\"\n",
    "mcf7_rep3_run1_pred = prediction(mcf7_rep3_run1_path)\n",
    "mcf7_rep3_run1_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcf7_rep3_run1_pred.to_csv(\"../data/aws_predictions/mcf7_rep3_run1_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119481, 76)\n",
      "119481\n",
      "Prediction file is of shape: (119481, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.009091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1013</td>\n",
       "      <td>0.009091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1149</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>512</td>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>689</td>\n",
       "      <td>0.009091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transcript  position     score\n",
       "0  ENST00000373020      1006  0.009091\n",
       "1  ENST00000373020      1013  0.009091\n",
       "2  ENST00000373020      1149  0.000000\n",
       "3  ENST00000373020       512  0.018182\n",
       "4  ENST00000373020       689  0.009091"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcf7_rep4_run1_path = \"/Users/claudia/Downloads/MCF7_rep4_run1.csv\"\n",
    "mcf7_rep4_run1_pred = prediction(mcf7_rep4_run1_path)\n",
    "mcf7_rep4_run1_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcf7_rep4_run1_pred.to_csv(\"../data/aws_predictions/mcf7_rep4_run1_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/claudia/DSA4262-ACMXZ/prediction'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data.JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to get key of a dictionary\n",
    "def get_key(dictionary):\n",
    "    key_object = dictionary.keys()\n",
    "    key = list(key_object)[0]\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to help concatenate columns to get transcript, position, nucleotides\n",
    "def concat_col(transcript, position, nucleotide, n):\n",
    "    t_df = pd.DataFrame([transcript]*n)\n",
    "    p_df = pd.DataFrame([position]*n)\n",
    "    nu_df = pd.DataFrame([nucleotide]*n)\n",
    "    n_df = pd.DataFrame([n]*n)\n",
    "\n",
    "    ## concat columns together\n",
    "    final_df = pd.concat([t_df, p_df, nu_df, n_df], axis = 1)\n",
    "    final_df.columns = ['transcript', 'position', 'nucleotides', 'reads_count']\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to parse line in json file\n",
    "def parse_line(line):\n",
    "    ## get transcript\n",
    "    t = get_key(line)\n",
    "\n",
    "    ## get position\n",
    "    p = get_key(line[t])\n",
    "\n",
    "    ## get nucleotide seq\n",
    "    nu = get_key(line[t][p])\n",
    "\n",
    "    ## get number of reads\n",
    "    reads_count = len(line[t][p][nu])\n",
    "\n",
    "    ## get dataframe of list of reads\n",
    "    reads = pd.DataFrame(line[t][p][nu])\n",
    "\n",
    "    ## concat columns together to get transcript, position, nucleotides and all dwelling time, std, mean\n",
    "    df = pd.concat([concat_col(t, p, nu, reads_count), reads], axis = 1)\n",
    "    df.columns = ['transcript', 'position', 'nucleotides', 'reads_count', 'dwellingtime_-1', 'std_-1', 'mean_-1', 'dwellingtime_0', 'std_0', 'mean_0', 'dwellingtime_+1', 'std_+1', 'mean_+1']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>nucleotides</th>\n",
       "      <th>reads_count</th>\n",
       "      <th>dwellingtime_-1</th>\n",
       "      <th>std_-1</th>\n",
       "      <th>mean_-1</th>\n",
       "      <th>dwellingtime_0</th>\n",
       "      <th>std_0</th>\n",
       "      <th>mean_0</th>\n",
       "      <th>dwellingtime_+1</th>\n",
       "      <th>std_+1</th>\n",
       "      <th>mean_+1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>185</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>10.40</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.00930</td>\n",
       "      <td>10.90</td>\n",
       "      <td>84.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>185</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>2.53</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>4.67</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.01030</td>\n",
       "      <td>6.30</td>\n",
       "      <td>80.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>185</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>3.92</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>12.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>2.13</td>\n",
       "      <td>79.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>185</td>\n",
       "      <td>0.00398</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>5.01</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>3.78</td>\n",
       "      <td>80.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>185</td>\n",
       "      <td>0.00664</td>\n",
       "      <td>2.92</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.00266</td>\n",
       "      <td>3.94</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.01300</td>\n",
       "      <td>7.15</td>\n",
       "      <td>82.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transcript position nucleotides  reads_count  dwellingtime_-1  std_-1  \\\n",
       "0  ENST00000000233      244     AAGACCA          185          0.00299    2.06   \n",
       "1  ENST00000000233      244     AAGACCA          185          0.00631    2.53   \n",
       "2  ENST00000000233      244     AAGACCA          185          0.00465    3.92   \n",
       "3  ENST00000000233      244     AAGACCA          185          0.00398    2.06   \n",
       "4  ENST00000000233      244     AAGACCA          185          0.00664    2.92   \n",
       "\n",
       "   mean_-1  dwellingtime_0  std_0  mean_0  dwellingtime_+1  std_+1  mean_+1  \n",
       "0    125.0         0.01770  10.40   122.0          0.00930   10.90     84.1  \n",
       "1    125.0         0.00844   4.67   126.0          0.01030    6.30     80.9  \n",
       "2    109.0         0.01360  12.00   124.0          0.00498    2.13     79.6  \n",
       "3    125.0         0.00830   5.01   130.0          0.00498    3.78     80.4  \n",
       "4    120.0         0.00266   3.94   129.0          0.01300    7.15     82.2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0 = [json.loads(line) for line in open(\"/Users/claudia/Downloads/data.json\", 'r')]\n",
    "\n",
    "## parse all lines in json file into dataframe for concatenation\n",
    "reads0_df = [parse_line(data0[i]) for i in range(len(data0))]\n",
    "data0_df = pd.concat(reads0_df, axis = 0)\n",
    "data0_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../util/model/\"))\n",
    "from training import get_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_id and labels removed from groupby and temp.columns\n",
    "def feature_eng(df):\n",
    "    temp = pd.DataFrame(df.groupby(['transcript', 'position', 'nucleotides', 'reads_count'], as_index=False)\n",
    "                           .agg({'dwellingtime_-1': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'std_-1': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'mean_-1': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'dwellingtime_0': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'std_0': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'mean_0': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'dwellingtime_+1': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'std_+1': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max],\n",
    "                                'mean_+1': [get_percent(25), get_percent(50), get_percent(75), np.mean, np.min, np.max]}))\n",
    "    temp.columns = ['transcript', 'position', 'nucleotides', 'reads_count',\n",
    "                        'dwelling_time_-1_25', 'dwelling_time_-1_50', 'dwelling_time_-1_75', 'dwelling_time_-1_mean','dwelling_time_-1_min', 'dwelling_time_-1_max',\n",
    "                        'std_-1_25', 'std_-1_50', 'std_-1_75', 'std_-1_mean','std_-1_min', 'std_-1_max',\n",
    "                        'mean_-1_25', 'mean_-1_50', 'mean_-1_75', 'mean_-1_mean','mean_-1_min', 'mean_-1_max',\n",
    "                        'dwelling_time_0_25', 'dwelling_time_0_50', 'dwelling_time_0_75', 'dwelling_time_0_mean','dwelling_time_0_min','dwelling_time_0_max',\n",
    "                        'std_0_25', 'std_0_50', 'std_0_75', 'std_0_mean','std_0_min', 'std_0_max',\n",
    "                        'mean_0_25', 'mean_0_50', 'mean_0_75', 'mean_0_mean','mean_0_min', 'mean_0_max',\n",
    "                        'dwelling_time_+1_25', 'dwelling_time_+1_50', 'dwelling_time_+1_75', 'dwelling_time_+1_mean','dwelling_time_+1_min','dwelling_time_+1_max',\n",
    "                        'std_+1_25', 'std_+1_50', 'std_+1_75', 'std_+1_mean','std_+1_min', 'std_+1_max',\n",
    "                        'mean_+1_25', 'mean_+1_50', 'mean_+1_75', 'mean_+1_mean','mean_+1_min', 'mean_+1_max']\n",
    "    return temp\n",
    "\n",
    "# gene_id removed from groupby\n",
    "def relative_position(df):\n",
    "    df[\"position\"] = df[\"position\"].astype(int)\n",
    "\n",
    "    ## find relative position of each read in each transcript\n",
    "    df[\"relative_position\"] = df.groupby([\"transcript\"])[\"position\"].transform(lambda x: (x - x.min())/(x.max()-x.min()))\n",
    "\n",
    "    ## note: have NAs because there's transcripts with only one position\n",
    "    ## fill the NAs with 0\n",
    "    df[\"relative_position\"] = df[\"relative_position\"].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "## variables needed for encoding\n",
    "pipe = pickle.load(open(\"../data/raw_data/encoding_pipeline.pkl\", \"rb\"))\n",
    "\n",
    "cols_to_map = ['reads_count', 'dwelling_time_-1_25', 'dwelling_time_-1_50', 'dwelling_time_-1_75', \n",
    "                'dwelling_time_-1_mean', 'dwelling_time_-1_min', 'dwelling_time_-1_max', 'std_-1_25', \n",
    "                'std_-1_50', 'std_-1_75', 'std_-1_mean', 'std_-1_min', 'std_-1_max', 'mean_-1_25', \n",
    "                'mean_-1_50', 'mean_-1_75', 'mean_-1_mean', 'mean_-1_min', 'mean_-1_max', \n",
    "                'dwelling_time_0_25', 'dwelling_time_0_50', 'dwelling_time_0_75', 'dwelling_time_0_mean', \n",
    "                'dwelling_time_0_min', 'dwelling_time_0_max', 'std_0_25', 'std_0_50', 'std_0_75', \n",
    "                'std_0_mean', 'std_0_min', 'std_0_max', 'mean_0_25', 'mean_0_50', 'mean_0_75', 'mean_0_mean', \n",
    "                'mean_0_min', 'mean_0_max', 'dwelling_time_+1_25', 'dwelling_time_+1_50', 'dwelling_time_+1_75', \n",
    "                'dwelling_time_+1_mean', 'dwelling_time_+1_min', 'dwelling_time_+1_max', 'std_+1_25', \n",
    "                'std_+1_50', 'std_+1_75', 'std_+1_mean', 'std_+1_min', 'std_+1_max', 'mean_+1_25', 'mean_+1_50', \n",
    "                'mean_+1_75', 'mean_+1_mean', 'mean_+1_min', 'mean_+1_max', 'relative_position', 'position_0_C', \n",
    "                'position_0_G', 'position_0_T', 'position_0_A', 'position_1_A', 'position_1_G', 'position_1_T', \n",
    "                'position_2_A', 'position_2_G', 'position_3_A', 'position_4_C', 'position_5_C', 'position_5_A', \n",
    "                'position_5_T', 'position_6_T', 'position_6_A', 'position_6_G', 'position_6_C']\n",
    "\n",
    "def encoding(df, columns_to_map):\n",
    "    id_val = df[['transcript','position']] ## needed to concat with pred proba for submission\n",
    "\n",
    "    for i in range(7):\n",
    "        df['position_' + str(i)] = df['nucleotides'].apply(lambda x: x[i])\n",
    "    \n",
    "    df_enc = pd.DataFrame({col: vals for vals, col in zip(pipe.transform(df).T, columns_to_map)})\n",
    "\n",
    "    return df_enc, id_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121838, 58)\n",
      "(121838, 59)\n",
      "(121838, 74) (121838, 2)\n"
     ]
    }
   ],
   "source": [
    "## preprocess dataset 1\n",
    "percentile_df0 = feature_eng(data0_df)\n",
    "print(percentile_df0.shape)\n",
    "\n",
    "relative_position_df0 = relative_position(percentile_df0)\n",
    "print(relative_position_df0.shape)\n",
    "\n",
    "encoded_df0, id_val_df0 = encoding(relative_position_df0, cols_to_map)\n",
    "print(encoded_df0.shape, id_val_df0.shape)\n",
    "\n",
    "data0_pp = encoded_df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121838\n",
      "(121838, 3)\n"
     ]
    }
   ],
   "source": [
    "data0_pred = pickled_model.predict_proba(data0_pp[rfe_features])[:,1]\n",
    "print(len(data0_pred))\n",
    "\n",
    "data0_res = pd.DataFrame(data0_pred, columns = ['score'])\n",
    "\n",
    "data0_res = pd.concat([id_val_df0, data0_res], axis = 1)\n",
    "print(data0_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data_path = \"../data/raw_data/data.info\"\n",
    "with open(info_data_path, 'r') as f:\n",
    "    info = f.read().splitlines()\n",
    "\n",
    "info_list = [info[i].split(\",\") for i in range(len(info))]\n",
    "info_df = pd.DataFrame(info_list[1:]) \n",
    "info_df.columns = info_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transcript     object\n",
       "position        int64\n",
       "score         float64\n",
       "gene_id        object\n",
       "label           int64\n",
       "0.0             int64\n",
       "0.001           int64\n",
       "0.002           int64\n",
       "0.003           int64\n",
       "0.004           int64\n",
       "0.005           int64\n",
       "0.006           int64\n",
       "0.007           int64\n",
       "0.008           int64\n",
       "0.009           int64\n",
       "0.01            int64\n",
       "0.011           int64\n",
       "0.012           int64\n",
       "0.013           int64\n",
       "0.014           int64\n",
       "postion        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0_pred_labels.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df[\"transcript_position\"] = info_df[\"transcript_position\"].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gene_id                object\n",
       "transcript_id          object\n",
       "transcript_position     int64\n",
       "label                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>score</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_position</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>316</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>332</td>\n",
       "      <td>0.009197</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>368</td>\n",
       "      <td>0.013737</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transcript  position     score          gene_id    transcript_id  \\\n",
       "0  ENST00000000233       244  0.009091  ENSG00000004059  ENST00000000233   \n",
       "1  ENST00000000233       261  0.000000  ENSG00000004059  ENST00000000233   \n",
       "2  ENST00000000233       316  0.027273  ENSG00000004059  ENST00000000233   \n",
       "3  ENST00000000233       332  0.009197  ENSG00000004059  ENST00000000233   \n",
       "4  ENST00000000233       368  0.013737  ENSG00000004059  ENST00000000233   \n",
       "\n",
       "   transcript_position label  \n",
       "0                  244     0  \n",
       "1                  261     0  \n",
       "2                  316     0  \n",
       "3                  332     0  \n",
       "4                  368     0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0_pred_labels = data0_res.merge(info_df, how = \"left\", left_on = [\"transcript\", \"position\"], right_on = [\"transcript_id\", \"transcript_position\"])\n",
    "data0_pred_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>score</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>316</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>332</td>\n",
       "      <td>0.009197</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>368</td>\n",
       "      <td>0.013737</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transcript  position     score          gene_id label\n",
       "0  ENST00000000233       244  0.009091  ENSG00000004059     0\n",
       "1  ENST00000000233       261  0.000000  ENSG00000004059     0\n",
       "2  ENST00000000233       316  0.027273  ENSG00000004059     0\n",
       "3  ENST00000000233       332  0.009197  ENSG00000004059     0\n",
       "4  ENST00000000233       368  0.013737  ENSG00000004059     0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data0_pred_labels = pd.concat([data0_res, info_df], axis = 1, join = \"outer\")\n",
    "data0_pred_labels.drop([\"transcript_id\", \"transcript_position\"], axis = 1, inplace = True)\n",
    "data0_pred_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.642337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          score\n",
       "label          \n",
       "0      0.023185\n",
       "1      0.642337"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0_pred_labels[[\"label\", \"score\"]].groupby([\"label\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>score</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>label</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.002</th>\n",
       "      <th>0.003</th>\n",
       "      <th>0.004</th>\n",
       "      <th>0.005</th>\n",
       "      <th>0.006</th>\n",
       "      <th>0.007</th>\n",
       "      <th>0.008</th>\n",
       "      <th>0.009</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.011</th>\n",
       "      <th>0.012</th>\n",
       "      <th>0.013</th>\n",
       "      <th>0.014</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>913</td>\n",
       "      <td>0.504545</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>2440</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.360568</td>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>2499</td>\n",
       "      <td>0.304545</td>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>ENST00000002596</td>\n",
       "      <td>1280</td>\n",
       "      <td>0.481818</td>\n",
       "      <td>ENSG00000002587</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121832</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>575</td>\n",
       "      <td>0.477536</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121833</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>610</td>\n",
       "      <td>0.628409</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121835</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>864</td>\n",
       "      <td>0.904545</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121836</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>926</td>\n",
       "      <td>0.895455</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121837</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>976</td>\n",
       "      <td>0.124039</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5475 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             transcript  position     score          gene_id  label  0.0  \\\n",
       "17      ENST00000000233       913  0.504545  ENSG00000004059      1    1   \n",
       "38      ENST00000000412      2440  0.818182  ENSG00000003056      1    1   \n",
       "39      ENST00000000412      2462  0.360568  ENSG00000003056      1    1   \n",
       "41      ENST00000000412      2499  0.304545  ENSG00000003056      1    1   \n",
       "136     ENST00000002596      1280  0.481818  ENSG00000002587      1    1   \n",
       "...                 ...       ...       ...              ...    ...  ...   \n",
       "121832  ENST00000641834       575  0.477536  ENSG00000167747      1    1   \n",
       "121833  ENST00000641834       610  0.628409  ENSG00000167747      1    1   \n",
       "121835  ENST00000641834       864  0.904545  ENSG00000167747      1    1   \n",
       "121836  ENST00000641834       926  0.895455  ENSG00000167747      1    1   \n",
       "121837  ENST00000641834       976  0.124039  ENSG00000167747      1    1   \n",
       "\n",
       "        0.001  0.002  0.003  0.004  0.005  0.006  0.007  0.008  0.009  0.01  \\\n",
       "17          1      1      1      1      1      1      1      1      1     1   \n",
       "38          1      1      1      1      1      1      1      1      1     1   \n",
       "39          1      1      1      1      1      1      1      1      1     1   \n",
       "41          1      1      1      1      1      1      1      1      1     1   \n",
       "136         1      1      1      1      1      1      1      1      1     1   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...   ...   \n",
       "121832      1      1      1      1      1      1      1      1      1     1   \n",
       "121833      1      1      1      1      1      1      1      1      1     1   \n",
       "121835      1      1      1      1      1      1      1      1      1     1   \n",
       "121836      1      1      1      1      1      1      1      1      1     1   \n",
       "121837      1      1      1      1      1      1      1      1      1     1   \n",
       "\n",
       "        0.011  0.012  0.013  0.014  \n",
       "17          1      1      1      1  \n",
       "38          1      1      1      1  \n",
       "39          1      1      1      1  \n",
       "41          1      1      1      1  \n",
       "136         1      1      1      1  \n",
       "...       ...    ...    ...    ...  \n",
       "121832      1      1      1      1  \n",
       "121833      1      1      1      1  \n",
       "121835      1      1      1      1  \n",
       "121836      1      1      1      1  \n",
       "121837      1      1      1      1  \n",
       "\n",
       "[5475 rows x 20 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0_pred_labels[data0_pred_labels[\"label\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1860972837.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>score</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>label</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.002</th>\n",
       "      <th>0.003</th>\n",
       "      <th>0.004</th>\n",
       "      <th>...</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.91</th>\n",
       "      <th>0.92</th>\n",
       "      <th>0.93</th>\n",
       "      <th>0.94</th>\n",
       "      <th>0.95</th>\n",
       "      <th>0.96</th>\n",
       "      <th>0.97</th>\n",
       "      <th>0.98</th>\n",
       "      <th>0.99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>316</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>332</td>\n",
       "      <td>0.009197</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>368</td>\n",
       "      <td>0.013737</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        transcript  position     score          gene_id  label  0.0  0.001  \\\n",
       "0  ENST00000000233       244  0.009091  ENSG00000004059      0    1      1   \n",
       "1  ENST00000000233       261  0.000000  ENSG00000004059      0    1      0   \n",
       "2  ENST00000000233       316  0.027273  ENSG00000004059      0    1      1   \n",
       "3  ENST00000000233       332  0.009197  ENSG00000004059      0    1      1   \n",
       "4  ENST00000000233       368  0.013737  ENSG00000004059      0    1      1   \n",
       "\n",
       "   0.002  0.003  0.004  ...  0.9  0.91  0.92  0.93  0.94  0.95  0.96  0.97  \\\n",
       "0      1      1      1  ...    0     0     0     0     0     0     0     0   \n",
       "1      0      0      0  ...    0     0     0     0     0     0     0     0   \n",
       "2      1      1      1  ...    0     0     0     0     0     0     0     0   \n",
       "3      1      1      1  ...    0     0     0     0     0     0     0     0   \n",
       "4      1      1      1  ...    0     0     0     0     0     0     0     0   \n",
       "\n",
       "   0.98  0.99  \n",
       "0     0     0  \n",
       "1     0     0  \n",
       "2     0     0  \n",
       "3     0     0  \n",
       "4     0     0  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0_pred_labels['label'] = data0_pred_labels['label'].astype(str).astype(int)\n",
    "numbers = [float(x)/100 for x in range(100)]\n",
    "for i in numbers:\n",
    "    data0_pred_labels[i] = data0_pred_labels.score.map(lambda x:1 if x>=i else 0)\n",
    "data0_pred_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_df = pd.DataFrame( columns = ['Probability','Accuracy','Sensitivity','Specificity', 'Precision',\"FNR\",'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Probability, Accuracy, Sensitivity, Specificity, FNR]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, auc, accuracy_score, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numbers:\n",
    "    cm1 = metrics.confusion_matrix(data0_pred_labels.label,data0_pred_labels[i])\n",
    "    \n",
    "    ## define roc metrics\n",
    "    y_pred = data0_pred_labels[i]\n",
    "    y_test = data0_pred_labels[\"label\"]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    ## plot roc curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label = 'Random Forest Classifier (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Random Forest Receiver operating characteristic')\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/2441805686.py:20: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  Precision = cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/2441805686.py:20: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  Precision = cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
      "/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/2441805686.py:20: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  Precision = cm1[1,1]/(cm1[1,1]+cm1[0,1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9d074dafa0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in numbers:\n",
    "    cm1 = metrics.confusion_matrix(data0_pred_labels.label,data0_pred_labels[i])\n",
    "\n",
    "    \"\"\" ## plot confusion matrix\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm1)\n",
    "    plt.title('Confusion matrix of the classifier')\n",
    "    fig.colorbar(cax)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show() \"\"\"\n",
    "\n",
    "    ## calculating accuracy score\n",
    "    total1 = sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    fnr = cm1[1,0]/(cm1[1,0]+cm1[1,1])\n",
    "    Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    Precision = cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
    "    f1 = 2*(Precision*Sensitivity)/(Precision+Sensitivity)\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,Sensitivity,Specificity, Precision,fnr,f1]\n",
    "    \n",
    "plt.plot(cutoff_df)\n",
    "plt.axvline(0.009)\n",
    "plt.show()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FNR</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.994386</td>\n",
       "      <td>0.902466</td>\n",
       "      <td>0.998711</td>\n",
       "      <td>0.970536</td>\n",
       "      <td>0.097534</td>\n",
       "      <td>0.935264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.33</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.994312</td>\n",
       "      <td>0.913425</td>\n",
       "      <td>0.998118</td>\n",
       "      <td>0.958046</td>\n",
       "      <td>0.086575</td>\n",
       "      <td>0.935203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.34</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.994337</td>\n",
       "      <td>0.907397</td>\n",
       "      <td>0.998427</td>\n",
       "      <td>0.964473</td>\n",
       "      <td>0.092603</td>\n",
       "      <td>0.935065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.32</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.994181</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.997671</td>\n",
       "      <td>0.948945</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.934248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.31</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.994115</td>\n",
       "      <td>0.925479</td>\n",
       "      <td>0.997345</td>\n",
       "      <td>0.942522</td>\n",
       "      <td>0.074521</td>\n",
       "      <td>0.933923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.36</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.994156</td>\n",
       "      <td>0.891507</td>\n",
       "      <td>0.998986</td>\n",
       "      <td>0.976395</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.932022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.37</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.994008</td>\n",
       "      <td>0.884384</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>0.980360</td>\n",
       "      <td>0.115616</td>\n",
       "      <td>0.929902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.993664</td>\n",
       "      <td>0.930959</td>\n",
       "      <td>0.996614</td>\n",
       "      <td>0.928246</td>\n",
       "      <td>0.069041</td>\n",
       "      <td>0.929601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.38</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.993910</td>\n",
       "      <td>0.879269</td>\n",
       "      <td>0.999304</td>\n",
       "      <td>0.983453</td>\n",
       "      <td>0.120731</td>\n",
       "      <td>0.928447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.29</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.993393</td>\n",
       "      <td>0.935890</td>\n",
       "      <td>0.996098</td>\n",
       "      <td>0.918609</td>\n",
       "      <td>0.064110</td>\n",
       "      <td>0.927169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.39</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.993680</td>\n",
       "      <td>0.871233</td>\n",
       "      <td>0.999441</td>\n",
       "      <td>0.986556</td>\n",
       "      <td>0.128767</td>\n",
       "      <td>0.925315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.28</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.993032</td>\n",
       "      <td>0.941005</td>\n",
       "      <td>0.995480</td>\n",
       "      <td>0.907362</td>\n",
       "      <td>0.058995</td>\n",
       "      <td>0.923877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.40</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.993500</td>\n",
       "      <td>0.864110</td>\n",
       "      <td>0.999587</td>\n",
       "      <td>0.989956</td>\n",
       "      <td>0.135890</td>\n",
       "      <td>0.922762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.27</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.992490</td>\n",
       "      <td>0.946119</td>\n",
       "      <td>0.994672</td>\n",
       "      <td>0.893103</td>\n",
       "      <td>0.053881</td>\n",
       "      <td>0.918847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.41</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.993032</td>\n",
       "      <td>0.852237</td>\n",
       "      <td>0.999656</td>\n",
       "      <td>0.991500</td>\n",
       "      <td>0.147763</td>\n",
       "      <td>0.916609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.26</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.991981</td>\n",
       "      <td>0.951233</td>\n",
       "      <td>0.993898</td>\n",
       "      <td>0.880027</td>\n",
       "      <td>0.048767</td>\n",
       "      <td>0.914246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.992720</td>\n",
       "      <td>0.844018</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.992909</td>\n",
       "      <td>0.155982</td>\n",
       "      <td>0.912430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.43</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.992367</td>\n",
       "      <td>0.835434</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.993700</td>\n",
       "      <td>0.164566</td>\n",
       "      <td>0.907720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.990873</td>\n",
       "      <td>0.955251</td>\n",
       "      <td>0.992549</td>\n",
       "      <td>0.857799</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>0.903906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.44</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.992022</td>\n",
       "      <td>0.826849</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>0.994726</td>\n",
       "      <td>0.173151</td>\n",
       "      <td>0.903052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.991727</td>\n",
       "      <td>0.818995</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.996223</td>\n",
       "      <td>0.181005</td>\n",
       "      <td>0.898957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.24</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.990184</td>\n",
       "      <td>0.959452</td>\n",
       "      <td>0.991630</td>\n",
       "      <td>0.843584</td>\n",
       "      <td>0.040548</td>\n",
       "      <td>0.897795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.46</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.991201</td>\n",
       "      <td>0.806393</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.997289</td>\n",
       "      <td>0.193607</td>\n",
       "      <td>0.891739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.23</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.989150</td>\n",
       "      <td>0.961826</td>\n",
       "      <td>0.990435</td>\n",
       "      <td>0.825521</td>\n",
       "      <td>0.038174</td>\n",
       "      <td>0.888476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.47</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.990766</td>\n",
       "      <td>0.796347</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>0.997712</td>\n",
       "      <td>0.203653</td>\n",
       "      <td>0.885729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.22</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.988271</td>\n",
       "      <td>0.965297</td>\n",
       "      <td>0.989352</td>\n",
       "      <td>0.810086</td>\n",
       "      <td>0.034703</td>\n",
       "      <td>0.880907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.48</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.990225</td>\n",
       "      <td>0.783927</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.998140</td>\n",
       "      <td>0.216073</td>\n",
       "      <td>0.878159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.21</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.987451</td>\n",
       "      <td>0.970046</td>\n",
       "      <td>0.988269</td>\n",
       "      <td>0.795536</td>\n",
       "      <td>0.029954</td>\n",
       "      <td>0.874167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.49</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.989790</td>\n",
       "      <td>0.773881</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.226119</td>\n",
       "      <td>0.871990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.989388</td>\n",
       "      <td>0.764749</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.998807</td>\n",
       "      <td>0.235251</td>\n",
       "      <td>0.866246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.985555</td>\n",
       "      <td>0.974612</td>\n",
       "      <td>0.986069</td>\n",
       "      <td>0.766997</td>\n",
       "      <td>0.025388</td>\n",
       "      <td>0.858430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.51</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.988600</td>\n",
       "      <td>0.746849</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999267</td>\n",
       "      <td>0.253151</td>\n",
       "      <td>0.854813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.19</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.984143</td>\n",
       "      <td>0.978630</td>\n",
       "      <td>0.984402</td>\n",
       "      <td>0.746968</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.847249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.52</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.987992</td>\n",
       "      <td>0.733151</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999502</td>\n",
       "      <td>0.266849</td>\n",
       "      <td>0.845854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.53</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.987451</td>\n",
       "      <td>0.721096</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999494</td>\n",
       "      <td>0.278904</td>\n",
       "      <td>0.837772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.18</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.982518</td>\n",
       "      <td>0.980091</td>\n",
       "      <td>0.982632</td>\n",
       "      <td>0.726411</td>\n",
       "      <td>0.019909</td>\n",
       "      <td>0.834396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.54</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.986884</td>\n",
       "      <td>0.708493</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999485</td>\n",
       "      <td>0.291507</td>\n",
       "      <td>0.829201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.55</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.986359</td>\n",
       "      <td>0.696804</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999476</td>\n",
       "      <td>0.303196</td>\n",
       "      <td>0.821136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.17</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.982648</td>\n",
       "      <td>0.980621</td>\n",
       "      <td>0.704650</td>\n",
       "      <td>0.017352</td>\n",
       "      <td>0.820748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.56</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.985637</td>\n",
       "      <td>0.680365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.319635</td>\n",
       "      <td>0.809783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.16</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.978463</td>\n",
       "      <td>0.985205</td>\n",
       "      <td>0.978146</td>\n",
       "      <td>0.679602</td>\n",
       "      <td>0.014795</td>\n",
       "      <td>0.804354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.57</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.985152</td>\n",
       "      <td>0.669589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.330411</td>\n",
       "      <td>0.802100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.58</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.984635</td>\n",
       "      <td>0.658082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.341918</td>\n",
       "      <td>0.793787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.59</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.984110</td>\n",
       "      <td>0.646393</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.353607</td>\n",
       "      <td>0.785223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.974417</td>\n",
       "      <td>0.987763</td>\n",
       "      <td>0.973789</td>\n",
       "      <td>0.639395</td>\n",
       "      <td>0.012237</td>\n",
       "      <td>0.776287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.983494</td>\n",
       "      <td>0.632694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.367306</td>\n",
       "      <td>0.775031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.61</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.982616</td>\n",
       "      <td>0.613151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.386849</td>\n",
       "      <td>0.760190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.14</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.971224</td>\n",
       "      <td>0.989406</td>\n",
       "      <td>0.970369</td>\n",
       "      <td>0.611055</td>\n",
       "      <td>0.010594</td>\n",
       "      <td>0.755509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.62</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.982099</td>\n",
       "      <td>0.601644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.398356</td>\n",
       "      <td>0.751283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.63</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.981525</td>\n",
       "      <td>0.588858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411142</td>\n",
       "      <td>0.741235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.13</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.967588</td>\n",
       "      <td>0.991050</td>\n",
       "      <td>0.966484</td>\n",
       "      <td>0.581814</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>0.733194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.64</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.980802</td>\n",
       "      <td>0.572785</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.427215</td>\n",
       "      <td>0.728371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.980129</td>\n",
       "      <td>0.557808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.442192</td>\n",
       "      <td>0.716145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>0.992146</td>\n",
       "      <td>0.961629</td>\n",
       "      <td>0.548853</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>0.706740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.66</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.979046</td>\n",
       "      <td>0.533699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.466301</td>\n",
       "      <td>0.695963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.67</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.978381</td>\n",
       "      <td>0.518904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481096</td>\n",
       "      <td>0.683261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.11</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.957887</td>\n",
       "      <td>0.993973</td>\n",
       "      <td>0.956189</td>\n",
       "      <td>0.516319</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.679613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.68</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.977601</td>\n",
       "      <td>0.501553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498447</td>\n",
       "      <td>0.668045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.69</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.976740</td>\n",
       "      <td>0.482374</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517626</td>\n",
       "      <td>0.650813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.976083</td>\n",
       "      <td>0.467763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.532237</td>\n",
       "      <td>0.637382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.948620</td>\n",
       "      <td>0.995068</td>\n",
       "      <td>0.946435</td>\n",
       "      <td>0.466398</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>0.635113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.71</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.974893</td>\n",
       "      <td>0.441279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.558721</td>\n",
       "      <td>0.612343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.09</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.940503</td>\n",
       "      <td>0.995616</td>\n",
       "      <td>0.937910</td>\n",
       "      <td>0.430025</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.600628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.72</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.974179</td>\n",
       "      <td>0.425388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.574612</td>\n",
       "      <td>0.596873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.73</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.973309</td>\n",
       "      <td>0.406027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.593973</td>\n",
       "      <td>0.577553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.931056</td>\n",
       "      <td>0.996712</td>\n",
       "      <td>0.927967</td>\n",
       "      <td>0.394320</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.565082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.74</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.972504</td>\n",
       "      <td>0.388128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.611872</td>\n",
       "      <td>0.559211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.971799</td>\n",
       "      <td>0.372420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627580</td>\n",
       "      <td>0.542720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.07</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.997626</td>\n",
       "      <td>0.915351</td>\n",
       "      <td>0.356714</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.525521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.76</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.970526</td>\n",
       "      <td>0.344110</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.655890</td>\n",
       "      <td>0.512026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.77</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.969730</td>\n",
       "      <td>0.326393</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673607</td>\n",
       "      <td>0.492151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.903749</td>\n",
       "      <td>0.998174</td>\n",
       "      <td>0.899306</td>\n",
       "      <td>0.318065</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.482412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.78</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.968975</td>\n",
       "      <td>0.309589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690411</td>\n",
       "      <td>0.472803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.79</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.968007</td>\n",
       "      <td>0.288037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.711963</td>\n",
       "      <td>0.447249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.967137</td>\n",
       "      <td>0.268676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731324</td>\n",
       "      <td>0.423553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.872035</td>\n",
       "      <td>0.998721</td>\n",
       "      <td>0.866074</td>\n",
       "      <td>0.259738</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.412259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.81</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.965873</td>\n",
       "      <td>0.240548</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759452</td>\n",
       "      <td>0.387809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.82</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.964929</td>\n",
       "      <td>0.219543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780457</td>\n",
       "      <td>0.360042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.839598</td>\n",
       "      <td>0.998904</td>\n",
       "      <td>0.832103</td>\n",
       "      <td>0.218708</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.358846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.83</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.963788</td>\n",
       "      <td>0.194155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805845</td>\n",
       "      <td>0.325176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.03</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.793529</td>\n",
       "      <td>0.999269</td>\n",
       "      <td>0.783849</td>\n",
       "      <td>0.178657</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.303119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.84</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.962721</td>\n",
       "      <td>0.170411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.829589</td>\n",
       "      <td>0.291199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.961703</td>\n",
       "      <td>0.147763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852237</td>\n",
       "      <td>0.257479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.722197</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>0.709134</td>\n",
       "      <td>0.139217</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.244402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.86</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.960489</td>\n",
       "      <td>0.120731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879269</td>\n",
       "      <td>0.215450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.87</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>0.101005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898995</td>\n",
       "      <td>0.183477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.597227</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>0.578285</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.182403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.88</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.958699</td>\n",
       "      <td>0.080913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919087</td>\n",
       "      <td>0.149713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.89</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.957862</td>\n",
       "      <td>0.062283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937717</td>\n",
       "      <td>0.117263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.957189</td>\n",
       "      <td>0.047306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952694</td>\n",
       "      <td>0.090338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.044937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.91</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.956335</td>\n",
       "      <td>0.028311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971689</td>\n",
       "      <td>0.055062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.92</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.955868</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982100</td>\n",
       "      <td>0.035170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.93</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989041</td>\n",
       "      <td>0.021680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.94</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.955383</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992877</td>\n",
       "      <td>0.014146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.955219</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996530</td>\n",
       "      <td>0.006917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.96</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.955088</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.001095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.97</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.955063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.98</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.955063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.99</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.955063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Probability  Accuracy  Sensitivity  Specificity  Precision       FNR  \\\n",
       "0.35         0.35  0.994386     0.902466     0.998711   0.970536  0.097534   \n",
       "0.33         0.33  0.994312     0.913425     0.998118   0.958046  0.086575   \n",
       "0.34         0.34  0.994337     0.907397     0.998427   0.964473  0.092603   \n",
       "0.32         0.32  0.994181     0.920000     0.997671   0.948945  0.080000   \n",
       "0.31         0.31  0.994115     0.925479     0.997345   0.942522  0.074521   \n",
       "0.36         0.36  0.994156     0.891507     0.998986   0.976395  0.108493   \n",
       "0.37         0.37  0.994008     0.884384     0.999166   0.980360  0.115616   \n",
       "0.30         0.30  0.993664     0.930959     0.996614   0.928246  0.069041   \n",
       "0.38         0.38  0.993910     0.879269     0.999304   0.983453  0.120731   \n",
       "0.29         0.29  0.993393     0.935890     0.996098   0.918609  0.064110   \n",
       "0.39         0.39  0.993680     0.871233     0.999441   0.986556  0.128767   \n",
       "0.28         0.28  0.993032     0.941005     0.995480   0.907362  0.058995   \n",
       "0.40         0.40  0.993500     0.864110     0.999587   0.989956  0.135890   \n",
       "0.27         0.27  0.992490     0.946119     0.994672   0.893103  0.053881   \n",
       "0.41         0.41  0.993032     0.852237     0.999656   0.991500  0.147763   \n",
       "0.26         0.26  0.991981     0.951233     0.993898   0.880027  0.048767   \n",
       "0.42         0.42  0.992720     0.844018     0.999716   0.992909  0.155982   \n",
       "0.43         0.43  0.992367     0.835434     0.999751   0.993700  0.164566   \n",
       "0.25         0.25  0.990873     0.955251     0.992549   0.857799  0.044749   \n",
       "0.44         0.44  0.992022     0.826849     0.999794   0.994726  0.173151   \n",
       "0.45         0.45  0.991727     0.818995     0.999854   0.996223  0.181005   \n",
       "0.24         0.24  0.990184     0.959452     0.991630   0.843584  0.040548   \n",
       "0.46         0.46  0.991201     0.806393     0.999897   0.997289  0.193607   \n",
       "0.23         0.23  0.989150     0.961826     0.990435   0.825521  0.038174   \n",
       "0.47         0.47  0.990766     0.796347     0.999914   0.997712  0.203653   \n",
       "0.22         0.22  0.988271     0.965297     0.989352   0.810086  0.034703   \n",
       "0.48         0.48  0.990225     0.783927     0.999931   0.998140  0.216073   \n",
       "0.21         0.21  0.987451     0.970046     0.988269   0.795536  0.029954   \n",
       "0.49         0.49  0.989790     0.773881     0.999948   0.998586  0.226119   \n",
       "0.50         0.50  0.989388     0.764749     0.999957   0.998807  0.235251   \n",
       "0.20         0.20  0.985555     0.974612     0.986069   0.766997  0.025388   \n",
       "0.51         0.51  0.988600     0.746849     0.999974   0.999267  0.253151   \n",
       "0.19         0.19  0.984143     0.978630     0.984402   0.746968  0.021370   \n",
       "0.52         0.52  0.987992     0.733151     0.999983   0.999502  0.266849   \n",
       "0.53         0.53  0.987451     0.721096     0.999983   0.999494  0.278904   \n",
       "0.18         0.18  0.982518     0.980091     0.982632   0.726411  0.019909   \n",
       "0.54         0.54  0.986884     0.708493     0.999983   0.999485  0.291507   \n",
       "0.55         0.55  0.986359     0.696804     0.999983   0.999476  0.303196   \n",
       "0.17         0.17  0.980712     0.982648     0.980621   0.704650  0.017352   \n",
       "0.56         0.56  0.985637     0.680365     1.000000   1.000000  0.319635   \n",
       "0.16         0.16  0.978463     0.985205     0.978146   0.679602  0.014795   \n",
       "0.57         0.57  0.985152     0.669589     1.000000   1.000000  0.330411   \n",
       "0.58         0.58  0.984635     0.658082     1.000000   1.000000  0.341918   \n",
       "0.59         0.59  0.984110     0.646393     1.000000   1.000000  0.353607   \n",
       "0.15         0.15  0.974417     0.987763     0.973789   0.639395  0.012237   \n",
       "0.60         0.60  0.983494     0.632694     1.000000   1.000000  0.367306   \n",
       "0.61         0.61  0.982616     0.613151     1.000000   1.000000  0.386849   \n",
       "0.14         0.14  0.971224     0.989406     0.970369   0.611055  0.010594   \n",
       "0.62         0.62  0.982099     0.601644     1.000000   1.000000  0.398356   \n",
       "0.63         0.63  0.981525     0.588858     1.000000   1.000000  0.411142   \n",
       "0.13         0.13  0.967588     0.991050     0.966484   0.581814  0.008950   \n",
       "0.64         0.64  0.980802     0.572785     1.000000   1.000000  0.427215   \n",
       "0.65         0.65  0.980129     0.557808     1.000000   1.000000  0.442192   \n",
       "0.12         0.12  0.963000     0.992146     0.961629   0.548853  0.007854   \n",
       "0.66         0.66  0.979046     0.533699     1.000000   1.000000  0.466301   \n",
       "0.67         0.67  0.978381     0.518904     1.000000   1.000000  0.481096   \n",
       "0.11         0.11  0.957887     0.993973     0.956189   0.516319  0.006027   \n",
       "0.68         0.68  0.977601     0.501553     1.000000   1.000000  0.498447   \n",
       "0.69         0.69  0.976740     0.482374     1.000000   1.000000  0.517626   \n",
       "0.70         0.70  0.976083     0.467763     1.000000   1.000000  0.532237   \n",
       "0.10         0.10  0.948620     0.995068     0.946435   0.466398  0.004932   \n",
       "0.71         0.71  0.974893     0.441279     1.000000   1.000000  0.558721   \n",
       "0.09         0.09  0.940503     0.995616     0.937910   0.430025  0.004384   \n",
       "0.72         0.72  0.974179     0.425388     1.000000   1.000000  0.574612   \n",
       "0.73         0.73  0.973309     0.406027     1.000000   1.000000  0.593973   \n",
       "0.08         0.08  0.931056     0.996712     0.927967   0.394320  0.003288   \n",
       "0.74         0.74  0.972504     0.388128     1.000000   1.000000  0.611872   \n",
       "0.75         0.75  0.971799     0.372420     1.000000   1.000000  0.627580   \n",
       "0.07         0.07  0.919048     0.997626     0.915351   0.356714  0.002374   \n",
       "0.76         0.76  0.970526     0.344110     1.000000   1.000000  0.655890   \n",
       "0.77         0.77  0.969730     0.326393     1.000000   1.000000  0.673607   \n",
       "0.06         0.06  0.903749     0.998174     0.899306   0.318065  0.001826   \n",
       "0.78         0.78  0.968975     0.309589     1.000000   1.000000  0.690411   \n",
       "0.79         0.79  0.968007     0.288037     1.000000   1.000000  0.711963   \n",
       "0.80         0.80  0.967137     0.268676     1.000000   1.000000  0.731324   \n",
       "0.05         0.05  0.872035     0.998721     0.866074   0.259738  0.001279   \n",
       "0.81         0.81  0.965873     0.240548     1.000000   1.000000  0.759452   \n",
       "0.82         0.82  0.964929     0.219543     1.000000   1.000000  0.780457   \n",
       "0.04         0.04  0.839598     0.998904     0.832103   0.218708  0.001096   \n",
       "0.83         0.83  0.963788     0.194155     1.000000   1.000000  0.805845   \n",
       "0.03         0.03  0.793529     0.999269     0.783849   0.178657  0.000731   \n",
       "0.84         0.84  0.962721     0.170411     1.000000   1.000000  0.829589   \n",
       "0.85         0.85  0.961703     0.147763     1.000000   1.000000  0.852237   \n",
       "0.02         0.02  0.722197     0.999817     0.709134   0.139217  0.000183   \n",
       "0.86         0.86  0.960489     0.120731     1.000000   1.000000  0.879269   \n",
       "0.87         0.87  0.959602     0.101005     1.000000   1.000000  0.898995   \n",
       "0.01         0.01  0.597227     0.999817     0.578285   0.100356  0.000183   \n",
       "0.88         0.88  0.958699     0.080913     1.000000   1.000000  0.919087   \n",
       "0.89         0.89  0.957862     0.062283     1.000000   1.000000  0.937717   \n",
       "0.90         0.90  0.957189     0.047306     1.000000   1.000000  0.952694   \n",
       "0.00         0.00  0.044937     1.000000     0.000000   0.044937  0.000000   \n",
       "0.91         0.91  0.956335     0.028311     1.000000   1.000000  0.971689   \n",
       "0.92         0.92  0.955868     0.017900     1.000000   1.000000  0.982100   \n",
       "0.93         0.93  0.955556     0.010959     1.000000   1.000000  0.989041   \n",
       "0.94         0.94  0.955383     0.007123     1.000000   1.000000  0.992877   \n",
       "0.95         0.95  0.955219     0.003470     1.000000   1.000000  0.996530   \n",
       "0.96         0.96  0.955088     0.000548     1.000000   1.000000  0.999452   \n",
       "0.97         0.97  0.955063     0.000000     1.000000        NaN  1.000000   \n",
       "0.98         0.98  0.955063     0.000000     1.000000        NaN  1.000000   \n",
       "0.99         0.99  0.955063     0.000000     1.000000        NaN  1.000000   \n",
       "\n",
       "            f1  \n",
       "0.35  0.935264  \n",
       "0.33  0.935203  \n",
       "0.34  0.935065  \n",
       "0.32  0.934248  \n",
       "0.31  0.933923  \n",
       "0.36  0.932022  \n",
       "0.37  0.929902  \n",
       "0.30  0.929601  \n",
       "0.38  0.928447  \n",
       "0.29  0.927169  \n",
       "0.39  0.925315  \n",
       "0.28  0.923877  \n",
       "0.40  0.922762  \n",
       "0.27  0.918847  \n",
       "0.41  0.916609  \n",
       "0.26  0.914246  \n",
       "0.42  0.912430  \n",
       "0.43  0.907720  \n",
       "0.25  0.903906  \n",
       "0.44  0.903052  \n",
       "0.45  0.898957  \n",
       "0.24  0.897795  \n",
       "0.46  0.891739  \n",
       "0.23  0.888476  \n",
       "0.47  0.885729  \n",
       "0.22  0.880907  \n",
       "0.48  0.878159  \n",
       "0.21  0.874167  \n",
       "0.49  0.871990  \n",
       "0.50  0.866246  \n",
       "0.20  0.858430  \n",
       "0.51  0.854813  \n",
       "0.19  0.847249  \n",
       "0.52  0.845854  \n",
       "0.53  0.837772  \n",
       "0.18  0.834396  \n",
       "0.54  0.829201  \n",
       "0.55  0.821136  \n",
       "0.17  0.820748  \n",
       "0.56  0.809783  \n",
       "0.16  0.804354  \n",
       "0.57  0.802100  \n",
       "0.58  0.793787  \n",
       "0.59  0.785223  \n",
       "0.15  0.776287  \n",
       "0.60  0.775031  \n",
       "0.61  0.760190  \n",
       "0.14  0.755509  \n",
       "0.62  0.751283  \n",
       "0.63  0.741235  \n",
       "0.13  0.733194  \n",
       "0.64  0.728371  \n",
       "0.65  0.716145  \n",
       "0.12  0.706740  \n",
       "0.66  0.695963  \n",
       "0.67  0.683261  \n",
       "0.11  0.679613  \n",
       "0.68  0.668045  \n",
       "0.69  0.650813  \n",
       "0.70  0.637382  \n",
       "0.10  0.635113  \n",
       "0.71  0.612343  \n",
       "0.09  0.600628  \n",
       "0.72  0.596873  \n",
       "0.73  0.577553  \n",
       "0.08  0.565082  \n",
       "0.74  0.559211  \n",
       "0.75  0.542720  \n",
       "0.07  0.525521  \n",
       "0.76  0.512026  \n",
       "0.77  0.492151  \n",
       "0.06  0.482412  \n",
       "0.78  0.472803  \n",
       "0.79  0.447249  \n",
       "0.80  0.423553  \n",
       "0.05  0.412259  \n",
       "0.81  0.387809  \n",
       "0.82  0.360042  \n",
       "0.04  0.358846  \n",
       "0.83  0.325176  \n",
       "0.03  0.303119  \n",
       "0.84  0.291199  \n",
       "0.85  0.257479  \n",
       "0.02  0.244402  \n",
       "0.86  0.215450  \n",
       "0.87  0.183477  \n",
       "0.01  0.182403  \n",
       "0.88  0.149713  \n",
       "0.89  0.117263  \n",
       "0.90  0.090338  \n",
       "0.00  0.086008  \n",
       "0.91  0.055062  \n",
       "0.92  0.035170  \n",
       "0.93  0.021680  \n",
       "0.94  0.014146  \n",
       "0.95  0.006917  \n",
       "0.96  0.001095  \n",
       "0.97       NaN  \n",
       "0.98       NaN  \n",
       "0.99       NaN  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_df.sort_values(\"f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_df \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Youtube Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.96818182e+00, 9.68181818e-01, 9.59090909e-01, ...,\n",
       "       3.21460718e-06, 3.15437512e-06, 0.00000000e+00])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Calculate the ROc Curve\n",
    "y_test = data0_pred_labels[\"label\"]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, data0_pred_labels[\"score\"])\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.994476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.340987</td>\n",
       "      <td>0.994476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.340963</td>\n",
       "      <td>0.994468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.341018</td>\n",
       "      <td>0.994468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.994443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     thresholds  accuracy\n",
       "376    0.340909  0.994476\n",
       "374    0.340987  0.994476\n",
       "375    0.340963  0.994468\n",
       "373    0.341018  0.994468\n",
       "370    0.345455  0.994443"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_ls = []\n",
    "for thres in thresholds:\n",
    "    y_pred = np.where(data0_pred_labels[\"score\"]>thres,1,0)\n",
    "    accuracy_ls.append(accuracy_score(y_test, y_pred, normalize=True))\n",
    "    \n",
    "accuracy_ls = pd.concat([pd.Series(thresholds), pd.Series(accuracy_ls)],\n",
    "                        axis=1)\n",
    "accuracy_ls.columns = ['thresholds', 'accuracy']\n",
    "accuracy_ls.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "accuracy_ls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thresholds    1.968182\n",
       "accuracy      0.994476\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_ls.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "A549_rep5_run1 = pd.read_csv(\"../data/aws_predictions/A549_rep5_run1_prediction.csv\")\n",
    "A549_rep6_run1 = pd.read_csv(\"../data/aws_predictions/A549_rep6_run1_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1013</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1149</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>512</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>689</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transcript  position     score  label\n",
       "0  ENST00000373020      1006  0.004545      0\n",
       "1  ENST00000373020      1013  0.009091      0\n",
       "2  ENST00000373020      1149  0.004545      0\n",
       "3  ENST00000373020       512  0.013636      0\n",
       "4  ENST00000373020       689  0.004545      0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A549_rep5_run1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "A549_rep5_run1[\"label\"] = A549_rep5_run1.score.map(lambda x:1 if x>=0.35 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "A549_rep6_run1[\"label\"] = A549_rep6_run1.score.map(lambda x:1 if x>=0.35 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.031818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1013</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>512</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>689</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transcript  position     score  label\n",
       "0  ENST00000373020      1006  0.031818      0\n",
       "1  ENST00000373020      1013  0.009091      0\n",
       "2  ENST00000373020      1149  0.000000      0\n",
       "3  ENST00000373020       512  0.036364      0\n",
       "4  ENST00000373020       689  0.027273      0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A549_rep6_run1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>position</th>\n",
       "      <th>score</th>\n",
       "      <th>label_x</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_position</th>\n",
       "      <th>label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1013</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1149</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>1149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>512</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>689</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>ENST00000373020</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transcript  position     score  label_x          gene_id  \\\n",
       "0  ENST00000373020      1006  0.004545        0  ENSG00000000003   \n",
       "1  ENST00000373020      1013  0.009091        0  ENSG00000000003   \n",
       "2  ENST00000373020      1149  0.004545        0  ENSG00000000003   \n",
       "3  ENST00000373020       512  0.013636        0  ENSG00000000003   \n",
       "4  ENST00000373020       689  0.004545        0  ENSG00000000003   \n",
       "\n",
       "     transcript_id  transcript_position label_y  \n",
       "0  ENST00000373020                 1006       0  \n",
       "1  ENST00000373020                 1013       0  \n",
       "2  ENST00000373020                 1149       0  \n",
       "3  ENST00000373020                  512       0  \n",
       "4  ENST00000373020                  689       0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = A549_rep5_run1.merge(info_df, how = \"left\", left_on = [\"transcript\", \"position\"], right_on = [\"transcript_id\", \"transcript_position\"])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test..isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true takes value in {'0', '1'} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hf/vxvn1cm55jncfc4dx4xp_q2h0000gn/T/ipykernel_7020/1481714797.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \"\"\"\n\u001b[0;32m--> 981\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    982\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnonzero_weight_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0mpos_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_pos_label_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;31m# make y_true a boolean vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_check_pos_label_consistency\u001b[0;34m(pos_label, y_true)\u001b[0m\n\u001b[1;32m    241\u001b[0m     ):\n\u001b[1;32m    242\u001b[0m         \u001b[0mclasses_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;34mf\"y_true takes value in {{{classes_repr}}} and pos_label is not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;34m\"specified: either make y_true take value in {0, 1} or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y_true takes value in {'0', '1'} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly."
     ]
    }
   ],
   "source": [
    "## define roc metrics\n",
    "y_pred = test.label_x\n",
    "y_test = test.label_y\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "## plot roc curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label = 'Random Forest Classifier (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Random Forest Receiver operating characteristic')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
